{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c2e386-5a9b-4982-884f-0a14ed8c0c2e",
   "metadata": {
    "id": "e4c2e386-5a9b-4982-884f-0a14ed8c0c2e"
   },
   "source": [
    "\n",
    "<font size = \"6\"> \"Î¤ext Classification with Pretrained Transformer models - Small Demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fdb395-3a0c-48aa-860e-3356e8eb0ab5",
   "metadata": {
    "id": "21fdb395-3a0c-48aa-860e-3356e8eb0ab5"
   },
   "source": [
    "## IMPORT THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fca19382-5913-4d00-897d-6579018c1395",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fca19382-5913-4d00-897d-6579018c1395",
    "outputId": "e5492053-6c5a-413b-e82e-2736503f8ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "------------------------------------------------\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "----------------------------------------------------\n",
      "Index(['review', 'sentiment'], dtype='object')\n",
      "----------------------------------------------------\n",
      "The labels of the dataset are: ['positive' 'negative']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load training set\n",
    "df = pd.read_csv(\"datasets/IMDB-Dataset.csv\")  # place your dataset\n",
    "print(df.head())\n",
    "print('------------------------------------------------')\n",
    "print(df.isna().sum())\n",
    "print('----------------------------------------------------')\n",
    "print(df.columns)\n",
    "print('----------------------------------------------------')\n",
    "labels = df.sentiment.unique()\n",
    "print(f'The labels of the dataset are: {labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ae5cff-89eb-4a67-99ed-3f11e080182c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90ae5cff-89eb-4a67-99ed-3f11e080182c",
    "outputId": "0fd30b77-30a3-43c3-9ddd-a3aa063208b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 40000\n",
      "Test size: 10000\n",
      "Updated Train size: 36000\n",
      "Validation size: 4000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X = df[\"review\"]\n",
    "#y = df[\"sentiment\"]\n",
    "\n",
    "X = [str(i) for i in df[\"review\"].values]\n",
    "y = [str(i) for i in df[\"sentiment\"].values]\n",
    "# Create a train/test split\n",
    "# Adjust test_size and random_state as you prefer\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,       # 20% of data goes to test\n",
    "    random_state=42,     # for reproducibility\n",
    "    stratify=y           # keeps class distribution balanced\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Test size:\", len(X_test))\n",
    "\n",
    "# For example, take 10% of the original training data to form a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(\"Updated Train size:\", len(X_train))\n",
    "print(\"Validation size:\", len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44d469-7d3d-4f61-836b-8c558423d37d",
   "metadata": {
    "id": "6c44d469-7d3d-4f61-836b-8c558423d37d"
   },
   "source": [
    "### COUNT THE TOTAL NUMBER OF THE TRAINING, DEVELOPMENT AND TEST SET EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95d88d7-1c05-4cbd-b402-bde16564bf05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c95d88d7-1c05-4cbd-b402-bde16564bf05",
    "outputId": "98b4c434-e3be-46ee-af41-820a05c7ad7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of the training examples is: 36000\n",
      "The total number of the development examples is: 4000\n",
      "The total number of the test examples is: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f'The total number of the training examples is: {len(X_train)}')\n",
    "print(f'The total number of the Validation examples is: {len(X_val)}')\n",
    "print(f'The total number of the test examples is: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3069507-3c6d-49fb-a597-68b469889b92",
   "metadata": {
    "id": "d3069507-3c6d-49fb-a597-68b469889b92"
   },
   "source": [
    "### EDA FOR THE DATASET...YOU KNOW WHAT TO DO!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b6c35-3ec3-49bb-9f69-ef65a139be2a",
   "metadata": {
    "id": "474b6c35-3ec3-49bb-9f69-ef65a139be2a"
   },
   "source": [
    "## PREPARE OUR DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a59964-fec6-40b4-882f-01526fcfb426",
   "metadata": {
    "id": "41a59964-fec6-40b4-882f-01526fcfb426"
   },
   "source": [
    "### AFTER THE PREPROCESS ENCODE THE LABELS (Y_TRAIN, Y_DEV, Y_TEST)\n",
    "\n",
    "We are going to use BertTokenizer in order to prepare our datasets for the training and evaluation of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b0b6b3-08d3-412d-9979-963bb7ada22e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6b0b6b3-08d3-412d-9979-963bb7ada22e",
    "outputId": "ef098224-1167-45ff-b593-3ee92a7008f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['a' 'e' 'g' 'i' 'n' 'o' 'p' 's' 't' 'v']\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Shape of encoded labels: (36000, 10)\n",
      "------------------------------------------------------------------------------------------------------\n",
      "[0 1 0 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Convert your list of lists of labels into a binarized form\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_encoded = mlb.fit_transform(y_train)\n",
    "\n",
    "# Check the classes that were encoded\n",
    "print(\"Classes:\", mlb.classes_)\n",
    "print('------------------------------------------------------------------------------------------------------')\n",
    "# Check the shape of the encoded labels\n",
    "print(\"Shape of encoded labels:\", y_train_encoded.shape)\n",
    "print('------------------------------------------------------------------------------------------------------')\n",
    "#print(y_train[5])\n",
    "print(y_train_encoded[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0517870f-5f87-4f1c-841c-a39acb6a7982",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0517870f-5f87-4f1c-841c-a39acb6a7982",
    "outputId": "aa171a1e-656f-4bcc-b51b-3872328e363c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['a' 'e' 'g' 'i' 'n' 'o' 'p' 's' 't' 'v']\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Shape of encoded labels: (4000, 10)\n",
      "------------------------------------------------------------------------------------------------------\n",
      "negative\n",
      "[1 1 1 1 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Convert your list of lists of labels into a binarized form\n",
    "y_val_encoded = mlb.transform(y_val)\n",
    "\n",
    "# Check the classes that were encoded\n",
    "print(\"Classes:\", mlb.classes_)\n",
    "print('------------------------------------------------------------------------------------------------------')\n",
    "# Check the shape of the encoded labels\n",
    "print(\"Shape of encoded labels:\", y_val_encoded.shape)\n",
    "print('------------------------------------------------------------------------------------------------------')\n",
    "print(y_val[5])\n",
    "print(y_val_encoded[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcca53cd-1742-4bae-be11-1a1d50943216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['a' 'e' 'g' 'i' 'n' 'o' 'p' 's' 't' 'v']\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Shape of encoded labels: (10000, 10)\n",
      "------------------------------------------------------------------------------------------------------\n",
      "[1 1 1 1 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Convert your list of lists of labels into a binarized form\n",
    "y_test_encoded = mlb.transform(y_test)\n",
    "\n",
    "# Check the classes that were encoded\n",
    "print(\"Classes:\", mlb.classes_)\n",
    "print('------------------------------------------------------------------------------------------------------')\n",
    "# Check the shape of the encoded labels\n",
    "print(\"Shape of encoded labels:\", y_test_encoded.shape)\n",
    "print('------------------------------------------------------------------------------------------------------')\n",
    "#print(y_test[5])\n",
    "print(y_test_encoded[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeea3eb-29e3-4618-a044-3c892b16719a",
   "metadata": {
    "id": "efeea3eb-29e3-4618-a044-3c892b16719a"
   },
   "source": [
    "### TRAIN A BASELINE MODEL (LOGISTIC REGRESSION) IN ORDER TO COMPARE IT WITH OUR MAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "XFManV1UFw0M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFManV1UFw0M",
    "outputId": "e0f224da-e20b-414f-faf3-ad16db4d9e6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amagklara\\PycharmProjects\\WordEmbeddings\\.venv\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label 1 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\amagklara\\PycharmProjects\\WordEmbeddings\\.venv\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label 3 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\amagklara\\PycharmProjects\\WordEmbeddings\\.venv\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label 8 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\amagklara\\PycharmProjects\\WordEmbeddings\\.venv\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label 9 is present in all training examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the training set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.92      0.90      0.91     18000\n",
      "           e       1.00      1.00      1.00     36000\n",
      "           g       0.92      0.90      0.91     18000\n",
      "           i       1.00      1.00      1.00     36000\n",
      "           n       0.92      0.90      0.91     18000\n",
      "           o       0.91      0.92      0.91     18000\n",
      "           p       0.91      0.92      0.91     18000\n",
      "           s       0.91      0.92      0.91     18000\n",
      "           t       1.00      1.00      1.00     36000\n",
      "           v       1.00      1.00      1.00     36000\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    252000\n",
      "   macro avg       0.95      0.95      0.95    252000\n",
      "weighted avg       0.96      0.96      0.96    252000\n",
      " samples avg       0.96      0.96      0.96    252000\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Classification Report for the training set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.90      0.88      0.89      2000\n",
      "           e       1.00      1.00      1.00      4000\n",
      "           g       0.90      0.88      0.89      2000\n",
      "           i       1.00      1.00      1.00      4000\n",
      "           n       0.90      0.88      0.89      2000\n",
      "           o       0.88      0.90      0.89      2000\n",
      "           p       0.88      0.90      0.89      2000\n",
      "           s       0.88      0.90      0.89      2000\n",
      "           t       1.00      1.00      1.00      4000\n",
      "           v       1.00      1.00      1.00      4000\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     28000\n",
      "   macro avg       0.93      0.93      0.93     28000\n",
      "weighted avg       0.95      0.95      0.95     28000\n",
      " samples avg       0.95      0.95      0.95     28000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train_final = X_train\n",
    "X_val_final = X_val\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train_final)\n",
    "X_val_vectorized = vectorizer.transform(X_val_final)\n",
    "\n",
    "\n",
    "# Use OneVsRestClassifier for multi-label classification\n",
    "model = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train_vectorized, y_train_encoded)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_pred = model.predict(X_train_vectorized)\n",
    "\n",
    "# Print the classification report for the training set\n",
    "print('Classification Report for the training set')\n",
    "print(classification_report(y_train_encoded, y_train_pred, target_names=mlb.classes_))\n",
    "print('---------------------------------------------------------------------------------')\n",
    "# Predict on the development set\n",
    "y_val_pred = model.predict(X_val_vectorized)\n",
    "\n",
    "# Print the classification report for the development set\n",
    "print('Classification Report for the training set')\n",
    "print(classification_report(y_val_encoded, y_val_pred, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9aea4-73fe-45b1-8a27-1fac0b8dc782",
   "metadata": {},
   "source": [
    "### INSTALL/IMPORT THE TWO MOST IMPORTANT LIBRARIES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "j_5YA5VmkNm7",
   "metadata": {
    "id": "j_5YA5VmkNm7"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install transformers==4.38.1\n",
    "# # Check the version of our package *transformer*\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82Bs5qdsnwfu",
   "metadata": {
    "id": "82Bs5qdsnwfu"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install torch==2.2.0 torchvision==0.14.1 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install torchmetrics torchtext --index-url https://download.pytorch.org/whl/cu118\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "IyEJA97fqOTU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IyEJA97fqOTU",
    "outputId": "1a01a24e-42fe-44b5-8c01-964f3313bb4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.49.0\n",
      "Torch version: 2.6.0+cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SUljuq02GQaO",
   "metadata": {
    "id": "SUljuq02GQaO"
   },
   "source": [
    "### TOKENIZE THE DATASETS VIA PRETRAINED TRANSFORMER MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a15e2b2-2cfd-45c7-8f13-6fc6039dc275",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458,
     "referenced_widgets": [
      "e6434f78ab0245f3b2d26cd018fb6ca7",
      "48b280114c054636b762c875674270d2",
      "297c843a7a154994a14ecb7f1ef9c9d7",
      "899c9baeefce400e8ba8bd5ed436e15b",
      "5f4f4cba040346ab9404cd725069b53d",
      "ab3f38544ee749a9a0845de0ede05e57",
      "30af6d69d3ce49af8f549c6ce551aa51",
      "1610c1ea2b42407eb600decd7630ca29",
      "838ca524ca5149ca9f671db0ad7ff499",
      "82aec999aae24841977994fda61be5fd",
      "582f6fe9f64541a1a7f470323ac1353e",
      "e5eb9833bc51423db4388bf4ddee33ca",
      "b945aee6e3b745119e3c5778e12317e0",
      "eb03754ef7c24cce93eee139db5828fc",
      "8ab7ec145b184cf88096a31dc2a003f3",
      "fb2806a1f15a4659a9aac5f0d44eda5f",
      "db33020dc294475ba460c365d47f6916",
      "e4a2f9220e074da99cc40ef5313aabc1",
      "f865858429f84129b6ac372fccaedfe0",
      "36bea91e235d4a0a9077f51e1046f02f",
      "814435c2139e44a8926f41f2b10404da",
      "0ef5592ce41f4f7e80e380fe13a5a301",
      "b16002561b004f3baa822435bce9fa0c",
      "86d98849cfc04ad38aea3eff62534d34",
      "3fd0d25872684109a253125d8b8a0bd9",
      "d16819ec3727469bba02f97570e993be",
      "bc771a9ca7e642e89e4ae31f94809308",
      "953105d495b74af4bfd737876682184f",
      "a4aa77150c5c44248f033da4398de66e",
      "7bd0ace0501544699abd287a730b7053",
      "264fd711ceb64a2abce06935f8696050",
      "bc39317b0ca54a6093adb33febc4816f",
      "dbf864f55be54e859c5e214c9d01309e"
     ]
    },
    "id": "3a15e2b2-2cfd-45c7-8f13-6fc6039dc275",
    "outputId": "b9e5632c-3c2b-45cc-c761-b491bbd7fb8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045, 2428,  ...,    0,    0,    0],\n",
       "        [ 101, 3100, 1010,  ...,    0,    0,    0],\n",
       "        [ 101, 2158, 1010,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2728, 2091,  ...,    0,    0,    0],\n",
       "        [ 101, 1044, 1012,  ...,    0,    0,    0],\n",
       "        [ 101, 1045, 2347,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Instantiate the BERT tokenizer with WordPiece tokenization\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "# Function for the tokenization\n",
    "def tokenize_text(data, tokenizer, max_length=MAX_SEQUENCE_LENGTH):\n",
    "    return tokenizer(data, padding='max_length',\n",
    "                     max_length=max_length, truncation=True, return_tensors='pt')\n",
    "\n",
    "\n",
    "bert_val = tokenize_text(X_val, bert_tokenizer)\n",
    "bert_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08674bde-d25a-4165-82dd-5724c28a6dcc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08674bde-d25a-4165-82dd-5724c28a6dcc",
    "outputId": "3d892f8b-95fb-43c5-f876-6aca98b3339b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1996, 3185,  ...,    0,    0,    0],\n",
       "        [ 101, 2023, 2003,  ...,    0,    0,    0],\n",
       "        [ 101, 2295, 1045,  ..., 2009, 1005,  102],\n",
       "        ...,\n",
       "        [ 101, 2023, 3185,  ...,    0,    0,    0],\n",
       "        [ 101, 3374, 1010,  ...,    0,    0,    0],\n",
       "        [ 101, 1045, 2428,  ..., 2136, 2988,  102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_train = tokenize_text(X_train, bert_tokenizer)\n",
    "bert_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21d44e0a-517b-44e0-9644-8eeb4490c21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2748, 1010,  ...,    0,    0,    0],\n",
       "        [ 101, 1996, 2466,  ...,    0,    0,    0],\n",
       "        [ 101, 1037, 2136,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2023, 2003,  ...,    0,    0,    0],\n",
       "        [ 101, 2023, 2003,  ...,    0,    0,    0],\n",
       "        [ 101, 6506, 9413,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_test = tokenize_text(X_test, bert_tokenizer)\n",
    "bert_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa434ad3-a392-4443-9798-904ac1b59dea",
   "metadata": {},
   "source": [
    "### LOAD THE PRETRAINED TRANSFORMER MODEL OF YOUR CHOICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "437d9772-9d08-4a96-bdec-4bac3f434625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "437d9772-9d08-4a96-bdec-4bac3f434625",
    "outputId": "46b4d88c-66c2-4075-8e35-c265f6c56fcb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "bert_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dktZaF9ezlbq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dktZaF9ezlbq",
    "outputId": "23a5a8f1-74f1-4181-9fdc-1d12d91cc6c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# Move your model to the selected device\n",
    "bert_model = bert_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b16dda-f3be-4792-9e60-83a843fd17c6",
   "metadata": {
    "id": "VekzJsoY4MB4"
   },
   "source": [
    "### TRANSFORM THE DATA INTO DATA LOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad087144-5c4b-460c-994d-effd1da82847",
   "metadata": {
    "id": "ad087144-5c4b-460c-994d-effd1da82847"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Make y_train, y_dev tensors\n",
    "y_train_encoded = torch.tensor(y_train_encoded)\n",
    "y_val_encoded = torch.tensor(y_val_encoded)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(bert_train['input_ids'], bert_train['attention_mask'], y_train_encoded)\n",
    "val_dataset = TensorDataset(bert_val['input_ids'], bert_val['attention_mask'], y_val_encoded)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd904f1c-88db-4f92-a94b-7536e296a0db",
   "metadata": {
    "id": "bd904f1c-88db-4f92-a94b-7536e296a0db"
   },
   "source": [
    "### UNFREEZE ALL THE TRANSFORMER LAYERS EXCEPT FOR EMBEDDING LAYER - YOU CAN MODIFY THAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8615a5f-0bc3-4b2d-9412-9b16faf78e5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8615a5f-0bc3-4b2d-9412-9b16faf78e5a",
    "outputId": "ceb5be1a-f666-4185-8bd3-2c2f5893a3a0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "param_freeze = ['bert.embeddings', 'bert.encoder.layer.0',\n",
    "                'bert.encoder.layer.1.', 'bert.encoder.layer.2',\n",
    "                'bert.encoder.layer.3', 'bert.encoder.layer.4',\n",
    "                'bert.encoder.layer.5']\n",
    "\n",
    "# Unfreeze the parameters of the classification head except the above\n",
    "for name, param in bert_model.named_parameters():\n",
    "    param.requires_grad = not any(name.startswith(prefix) for prefix in param_freeze)\n",
    "\n",
    "\n",
    "# Print the names of trainable parameters\n",
    "for name, param in bert_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c24e0a08-7d97-4fb4-8a53-92addde2e76a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c24e0a08-7d97-4fb4-8a53-92addde2e76a",
    "outputId": "09909f04-9b3d-49ec-9e24-45d81d563b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 43119362\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print the number of trainable parameters\n",
    "print(\"Number of trainable parameters:\", count_parameters(bert_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542fd205-62c7-4974-8db6-1d714329cf6b",
   "metadata": {},
   "source": [
    "### CUSTOM F1 SCORE CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "906aad66-92c5-4a02-a40a-fc1b7ff55a76",
   "metadata": {
    "id": "906aad66-92c5-4a02-a40a-fc1b7ff55a76"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "\n",
    "def f1_metric(logits, labels, threshold=0.5, zero_division=1):\n",
    "    \"\"\"\n",
    "    Calculate F1 score for multi-label classification.\n",
    "    Args:\n",
    "    - logits (torch.Tensor): Predicted logits for each class (batch_size x num_classes).\n",
    "    - labels (torch.Tensor): True labels for each class (batch_size x num_classes).\n",
    "    - threshold (float): Threshold for converting probabilities to binary predictions (default: 0.5).\n",
    "    - zero_division (int): Sets the value to return when there is a zero division. Use 0 or 1 (default: 1).\n",
    "\n",
    "    Returns:\n",
    "    - f1 (float): Average F1 score across all samples and classes.\n",
    "    \"\"\"\n",
    "    preds = torch.sigmoid(logits)  # Convert logits to probabilities using sigmoid\n",
    "    preds_binary = (preds > threshold).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    # Calculate F1 score for each class and then average\n",
    "    f1_per_class = f1_score(labels, preds_binary, average=None, zero_division=zero_division)\n",
    "    average_f1 = f1_per_class.mean()\n",
    "\n",
    "    return average_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb29d4-6429-40d3-9378-61deb5a8200a",
   "metadata": {},
   "source": [
    "### MAIN TRAINING SECTION - READ AGAIN CAREFULLY THE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876752ef-5f97-4e2c-b392-caca10b8ce87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "876752ef-5f97-4e2c-b392-caca10b8ce87",
    "outputId": "a22a844d-b8d2-4e6b-aab9-00cbfd88af7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For batch \"144\": Training - Loss: 0.478, F1 Score: 0.738'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, update_display\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Prepare optimizer and loss function\n",
    "optimizer = Adam(bert_model.parameters(), lr=1e-5)\n",
    "\n",
    "# Set up the ReduceLROnPlateau scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "# Updated loss function with weights\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Initialize a display object for updating output in-place\n",
    "display_id = 'batch_update'\n",
    "display_obj = display(\"\", display_id=display_id)\n",
    "\n",
    "# Initialize lists to store history\n",
    "train_losses = []\n",
    "train_f1_scores = []\n",
    "val_losses = []\n",
    "val_f1_scores = []\n",
    "patience = 0\n",
    "\n",
    "# Initialize variables to track best validation loss and corresponding model weights\n",
    "best_val_loss = float('inf')\n",
    "best_val_f1 = float('-inf')\n",
    "best_model_weights = None\n",
    "\n",
    "# Adjust the model's output layer, if not already adjusted\n",
    "bert_model.classifier = torch.nn.Linear(bert_model.config.hidden_size, 10)#len(labels)\n",
    "bert_model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    bert_model.train()\n",
    "    total_loss = 0\n",
    "    total_f1 = 0\n",
    "    cnt = 0\n",
    "    for batch in train_loader:\n",
    "        cnt += 1\n",
    "        optimizer.zero_grad()  # Reset gradients to zero for each batch\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)  # Move the tensors to the specified device\n",
    "        # Get model outputs (logits)\n",
    "        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #logits = torch.randn(16, 2)  # [batch_size, num_classes]\n",
    "        #labels = torch.randint(0, 2, (16,2))  # [batch_size] - class labels as integers\n",
    "        \n",
    "        logits = outputs.logits  # Ensure your model configuration aligns with this, or adjust as needed\n",
    "        \n",
    "        # Compute loss using the logits from the model and the labels from your dataset\n",
    "        loss = loss_function(logits, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_f1 += f1_metric(logits, labels)\n",
    "        # Update the displayed output for this batch\n",
    "        output = f'For batch \"{cnt}\": Training - Loss: {total_loss/cnt:.3f}, F1 Score: {total_f1/cnt:.3f}'\n",
    "        update_display(output, display_id=display_id)\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    avg_train_f1 = total_f1 / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_f1_scores.append(avg_train_f1)\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs}: Training - Loss: {avg_train_loss:.3f}, F1 Score: {avg_train_f1:.3f}')\n",
    "\n",
    "    # Validation loop\n",
    "    bert_model.eval()\n",
    "    total_val_loss = 0\n",
    "    total_val_f1 = 0\n",
    "    for batch in val_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)  # Move the tensors to the specified device\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            val_loss = loss_function(logits, labels.float())\n",
    "\n",
    "        total_val_loss += val_loss.item()\n",
    "        total_val_f1 += f1_metric(logits, labels)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    avg_val_f1 = total_val_f1 / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_f1_scores.append(avg_val_f1)\n",
    "\n",
    "    if avg_val_loss < best_val_loss or avg_val_f1 > best_val_f1:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_val_f1 = avg_val_f1\n",
    "        best_model_weights = bert_model.state_dict()\n",
    "        torch.save(best_model_weights, '/content/drive/MyDrive/best_model.pth')  # Make sure the path is correct and accessible\n",
    "        print(f'Validation improved, saving model to /content/drive/MyDrive/best_model.pth')\n",
    "        patience = 0\n",
    "    else:\n",
    "        print(f'Validation did not improve')\n",
    "        patience += 1\n",
    "        if patience >= 5:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "\n",
    "    print(f'Validation - Loss: {avg_val_loss:.3f}, F1 Score: {avg_val_f1:.3f}')\n",
    "    # Check the average validation loss and update the learning rate accordingly\n",
    "    scheduler.step(avg_val_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YPRJaiRe47Tf",
   "metadata": {
    "id": "YPRJaiRe47Tf"
   },
   "source": [
    "#### TRAINING CURVES FOR OUR TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "B4VWz-0G4iXw",
   "metadata": {
    "id": "B4VWz-0G4iXw"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(train_losses, train_f1_scores, val_losses, val_f1_scores):\n",
    "    \"\"\"\n",
    "    Plot the history of epochs for loss and accuracy\n",
    "    :param train_losses: List of training losses for each epoch\n",
    "    :param train_f1_scores: List of training f1 scores for each epoch\n",
    "    :param val_losses: List of validation losses for each epoch\n",
    "    :param val_f1_scores: List of validation f1 scores for each epoch\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Plot training and validation losses\n",
    "    plt.plot(epochs, train_losses, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_losses, 'r', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation f1 scores\n",
    "    plt.plot(epochs,train_f1_scores, 'b', label='Training f1-score')\n",
    "    plt.plot(epochs, val_f1_scores, 'r', label='Validation f1-score')\n",
    "    plt.title('Training and Validation =f1-scores')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('f1_score')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ZNGJDL-45G74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "ZNGJDL-45G74",
    "outputId": "2e724158-cd63-41ea-eccc-3cd30dcccf3e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m history_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtrain_losses\u001b[49m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_f1_scores\u001b[39m\u001b[38;5;124m'\u001b[39m: train_f1_scores,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_losses\u001b[39m\u001b[38;5;124m'\u001b[39m: val_losses,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_scores\u001b[39m\u001b[38;5;124m'\u001b[39m: val_f1_scores,\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      8\u001b[0m history_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(history_dict)\n\u001b[0;32m     10\u001b[0m history_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/history_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "history_dict = {\n",
    "    'train_losses': train_losses,\n",
    "    'train_f1_scores': train_f1_scores,\n",
    "    'val_losses': val_losses,\n",
    "    'f1_scores': val_f1_scores,\n",
    "}\n",
    "\n",
    "history_df = pd.DataFrame(history_dict)\n",
    "\n",
    "history_df.to_csv('/content/drive/MyDrive/history_results.csv', index=False)\n",
    "\n",
    "plot_history(train_losses, train_f1_scores, val_losses, val_f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5rBaE_Gef-Gg",
   "metadata": {
    "id": "5rBaE_Gef-Gg"
   },
   "source": [
    "#### EVALUATE THE TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aPCk0-ATVY1o",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPCk0-ATVY1o",
    "outputId": "7a663c26-c91f-4191-da23-90736057f27c"
   },
   "outputs": [],
   "source": [
    "# Evaluation on training data\n",
    "bert_model.eval()\n",
    "predictions_test = []\n",
    "true_labels_test = []\n",
    "\n",
    "for batch in train_loader:\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Apply sigmoid to the logits and then threshold to get binary predictions\n",
    "    predictions = torch.sigmoid(logits).cpu().numpy() > 0.3\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    # Extend the lists with the batch predictions and true labels\n",
    "    predictions_test.extend(predictions)\n",
    "    true_labels_test.extend(labels)\n",
    "\n",
    "# At this point, you have the true labels and predictions\n",
    "# You can then flatten these lists and use them in sklearn's classification_report\n",
    "true_labels_test = np.array(true_labels_test)\n",
    "predictions_test = np.array(predictions_test)\n",
    "\n",
    "# Assuming you want to evaluate at the individual label level\n",
    "print('Classification Report for the training set')\n",
    "print(classification_report(true_labels_test, predictions_test, target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "if1zx7cCepB8",
   "metadata": {
    "id": "if1zx7cCepB8"
   },
   "source": [
    "#### EVALUATE THE DEVELOPMENT SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qESoTwZR5J8s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qESoTwZR5J8s",
    "outputId": "3a160ce4-18c8-46d2-afca-0a3ff990ce12"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Evaluation on development data\n",
    "bert_model.eval()\n",
    "predictions_test = []\n",
    "true_labels_test = []\n",
    "\n",
    "for batch in val_loader:\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Apply sigmoid to the logits and then threshold to get binary predictions\n",
    "    probabilities = torch.sigmoid(logits).cpu().numpy()\n",
    "    predictions = probabilities > 0.3\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    # Extend the lists with the batch predictions and true labels\n",
    "    predictions_test.extend(predictions)\n",
    "    true_labels_test.extend(labels)\n",
    "\n",
    "# Flatten these lists and use them in sklearn's classification_report\n",
    "true_labels_test = np.array(true_labels_test)\n",
    "predictions_test = np.array(predictions_test)\n",
    "\n",
    "# Evaluate at the individual label level\n",
    "print('Classification Report for the development set')\n",
    "print(classification_report(true_labels_test, predictions_test, target_names=mlb.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ef5592ce41f4f7e80e380fe13a5a301": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1610c1ea2b42407eb600decd7630ca29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "264fd711ceb64a2abce06935f8696050": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "297c843a7a154994a14ecb7f1ef9c9d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1610c1ea2b42407eb600decd7630ca29",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_838ca524ca5149ca9f671db0ad7ff499",
      "value": 48
     }
    },
    "30af6d69d3ce49af8f549c6ce551aa51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36bea91e235d4a0a9077f51e1046f02f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3fd0d25872684109a253125d8b8a0bd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bd0ace0501544699abd287a730b7053",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_264fd711ceb64a2abce06935f8696050",
      "value": 466062
     }
    },
    "48b280114c054636b762c875674270d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab3f38544ee749a9a0845de0ede05e57",
      "placeholder": "â",
      "style": "IPY_MODEL_30af6d69d3ce49af8f549c6ce551aa51",
      "value": "tokenizer_config.json:â100%"
     }
    },
    "582f6fe9f64541a1a7f470323ac1353e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f4f4cba040346ab9404cd725069b53d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bd0ace0501544699abd287a730b7053": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "814435c2139e44a8926f41f2b10404da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82aec999aae24841977994fda61be5fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "838ca524ca5149ca9f671db0ad7ff499": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "86d98849cfc04ad38aea3eff62534d34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_953105d495b74af4bfd737876682184f",
      "placeholder": "â",
      "style": "IPY_MODEL_a4aa77150c5c44248f033da4398de66e",
      "value": "tokenizer.json:â100%"
     }
    },
    "899c9baeefce400e8ba8bd5ed436e15b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82aec999aae24841977994fda61be5fd",
      "placeholder": "â",
      "style": "IPY_MODEL_582f6fe9f64541a1a7f470323ac1353e",
      "value": "â48.0/48.0â[00:00&lt;00:00,â4.01kB/s]"
     }
    },
    "8ab7ec145b184cf88096a31dc2a003f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_814435c2139e44a8926f41f2b10404da",
      "placeholder": "â",
      "style": "IPY_MODEL_0ef5592ce41f4f7e80e380fe13a5a301",
      "value": "â232k/232kâ[00:00&lt;00:00,â542kB/s]"
     }
    },
    "953105d495b74af4bfd737876682184f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4aa77150c5c44248f033da4398de66e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab3f38544ee749a9a0845de0ede05e57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b16002561b004f3baa822435bce9fa0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86d98849cfc04ad38aea3eff62534d34",
       "IPY_MODEL_3fd0d25872684109a253125d8b8a0bd9",
       "IPY_MODEL_d16819ec3727469bba02f97570e993be"
      ],
      "layout": "IPY_MODEL_bc771a9ca7e642e89e4ae31f94809308"
     }
    },
    "b945aee6e3b745119e3c5778e12317e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db33020dc294475ba460c365d47f6916",
      "placeholder": "â",
      "style": "IPY_MODEL_e4a2f9220e074da99cc40ef5313aabc1",
      "value": "vocab.txt:â100%"
     }
    },
    "bc39317b0ca54a6093adb33febc4816f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc771a9ca7e642e89e4ae31f94809308": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d16819ec3727469bba02f97570e993be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc39317b0ca54a6093adb33febc4816f",
      "placeholder": "â",
      "style": "IPY_MODEL_dbf864f55be54e859c5e214c9d01309e",
      "value": "â466k/466kâ[00:00&lt;00:00,â28.7MB/s]"
     }
    },
    "db33020dc294475ba460c365d47f6916": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbf864f55be54e859c5e214c9d01309e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4a2f9220e074da99cc40ef5313aabc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5eb9833bc51423db4388bf4ddee33ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b945aee6e3b745119e3c5778e12317e0",
       "IPY_MODEL_eb03754ef7c24cce93eee139db5828fc",
       "IPY_MODEL_8ab7ec145b184cf88096a31dc2a003f3"
      ],
      "layout": "IPY_MODEL_fb2806a1f15a4659a9aac5f0d44eda5f"
     }
    },
    "e6434f78ab0245f3b2d26cd018fb6ca7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48b280114c054636b762c875674270d2",
       "IPY_MODEL_297c843a7a154994a14ecb7f1ef9c9d7",
       "IPY_MODEL_899c9baeefce400e8ba8bd5ed436e15b"
      ],
      "layout": "IPY_MODEL_5f4f4cba040346ab9404cd725069b53d"
     }
    },
    "eb03754ef7c24cce93eee139db5828fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f865858429f84129b6ac372fccaedfe0",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36bea91e235d4a0a9077f51e1046f02f",
      "value": 231508
     }
    },
    "f865858429f84129b6ac372fccaedfe0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb2806a1f15a4659a9aac5f0d44eda5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
